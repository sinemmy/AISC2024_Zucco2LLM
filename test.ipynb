{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.load_zuco_data import *\n",
    "import numpy as np\n",
    "import torch \n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from src.load_zuco_sentences import *\n",
    "from src.extract_llm_embeddings import *\n",
    "# tokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "# transformer lens\n",
    "import tqdm.auto as tqdm\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD SENTENCES from ZUCO data and SAVE into a CSV \n",
    "Do not need to re-run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sentences into a data frame \n",
    "sentence_data_file = '../zuco-benchmark/portable_data/sentence_content.json'\n",
    "# this file has all the sentences in the dataset seen by each subject\n",
    "df_sentences = load_zuco_dataframe(sentence_data_file)\n",
    "# we don't need the subject data, we just need the sentences - which will have unique indices for a task\n",
    "df2 = df_sentences[['task', 'index', 'sentence']].drop_duplicates(subset=['task', 'index'])\n",
    "# \n",
    "unique_sentences = df2.drop_duplicates(subset=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>TSR</td>\n",
       "      <td>379</td>\n",
       "      <td>In the 40s, Gillespie led the movement called ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>TSR</td>\n",
       "      <td>380</td>\n",
       "      <td>In 1867, his brother's company, Rockefeller &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>TSR</td>\n",
       "      <td>381</td>\n",
       "      <td>Married to Almira Geraldine Goodsell, he built...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>TSR</td>\n",
       "      <td>382</td>\n",
       "      <td>Libby was a founding member of the Project for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>TSR</td>\n",
       "      <td>383</td>\n",
       "      <td>He was elected to the Bulgarian national assem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>TSR</td>\n",
       "      <td>384</td>\n",
       "      <td>He also created the Defense Intelligence Agenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>TSR</td>\n",
       "      <td>385</td>\n",
       "      <td>He was one of the founder members of the Lunar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>TSR</td>\n",
       "      <td>387</td>\n",
       "      <td>He was the founder and first president of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>TSR</td>\n",
       "      <td>388</td>\n",
       "      <td>Her mother was a Lyman, another very old Ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>TSR</td>\n",
       "      <td>389</td>\n",
       "      <td>In 1999 Bush cofounded a educational-software ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    task  index                                           sentence\n",
       "728  TSR    379  In the 40s, Gillespie led the movement called ...\n",
       "729  TSR    380  In 1867, his brother's company, Rockefeller & ...\n",
       "730  TSR    381  Married to Almira Geraldine Goodsell, he built...\n",
       "731  TSR    382  Libby was a founding member of the Project for...\n",
       "732  TSR    383  He was elected to the Bulgarian national assem...\n",
       "733  TSR    384  He also created the Defense Intelligence Agenc...\n",
       "734  TSR    385  He was one of the founder members of the Lunar...\n",
       "736  TSR    387  He was the founder and first president of the ...\n",
       "737  TSR    388  Her mother was a Lyman, another very old Ameri...\n",
       "738  TSR    389  In 1999 Bush cofounded a educational-software ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sentences.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56 sentences that appear in both NR and TSR tasks:\n",
      "- When Baldwin was young, he had a job as a busboy at famous New York City disco Studio 54.\n",
      "- Frank J. Howard (March 25, 1909 - January 26, 1996) was an American college football player and coach.\n",
      "- She was First Lady of the United States from 1993 to 2001, as the wife of President Bill Clinton.\n",
      "- Clooney's first recordings, in May of 1946 were for Columbia Records as a singer with the big band of Tony Pastor.\n",
      "- Henry Ford, with his son Edsel, founded the Ford Foundation in 1936 as a local philanthropic organization with a broad charter to promote human welfare.\n",
      "- Erasmus Darwin (December 12, 1731 – April 18, 1802) trained as a physician and wrote extensively on medicine and botany, as well as poetry.\n",
      "- In 1986, Schwarzenegger married TV journalist Maria Shriver, niece of the late President of the United States John F. Kennedy.\n",
      "- After earning his degree, Bush went to work in an entry level position in the international division of Texas Commerce Bank, which was run by Ben Love.\n",
      "- He was, for a short time, a commentator opposite Bill Clinton on CBS's 60 Minutes.\n",
      "- He then enrolled at Phillips Andover, a private boarding school in Massachusetts already attended by his brother George.\n",
      "...and 46 more.\n"
     ]
    }
   ],
   "source": [
    "#let's check if there are duplicate sentences across tasks\n",
    "\n",
    "# Get set of sentences in each task\n",
    "nr_sentences = set(df2[df2['task'] == 'NR']['sentence'])\n",
    "tsr_sentences = set(df2[df2['task'] == 'TSR']['sentence'])\n",
    "\n",
    "# Find intersection\n",
    "common_sentences = nr_sentences.intersection(tsr_sentences)\n",
    "\n",
    "if common_sentences:\n",
    "    print(f\"Found {len(common_sentences)} sentences that appear in both NR and TSR tasks:\")\n",
    "    for sentence in list(common_sentences)[:10]:  # Show first 10 as example\n",
    "        print(f\"- {sentence}\")\n",
    "    if len(common_sentences) > 10:\n",
    "        print(f\"...and {len(common_sentences) - 10} more.\")\n",
    "else:\n",
    "    print(\"No sentences appear in both tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title: save csv (note that index = -100 if the sentence is not present in one of the tasks)\n",
    "\n",
    "# We want to get the senteces out for an LLM, so we only need the unique sentences. \n",
    "# We should however, keep track of the sentence index and which task(s) it was used in \n",
    "# We can do this by merging the two dataframes on the sentence column, and keeping the index from each task\n",
    "# We will also fill in the index with -100 for sentences that are not present in one of the tasks (in order to avoid nans)\n",
    "\n",
    "\n",
    "# Create two separate DataFrames for each task, dropping duplicates first\n",
    "nr_df = df2[df2['task'] == 'NR'][['index', 'sentence']].drop_duplicates(subset=['sentence']).rename(columns={'index': 'NR_index'})\n",
    "tsr_df = df2[df2['task'] == 'TSR'][['index', 'sentence']].drop_duplicates(subset=['sentence']).rename(columns={'index': 'TSR_index'})\n",
    "\n",
    "# Merge the DataFrames on the sentence, using outer join to keep all sentences\n",
    "result_df = pd.merge(nr_df, tsr_df, on='sentence', how='outer')\n",
    "\n",
    "# Fill NaN values with -100\n",
    "result_df = result_df.fillna(-100)\n",
    "\n",
    "# Convert indices to integers\n",
    "result_df['NR_index'] = result_df['NR_index'].astype(int)\n",
    "result_df['TSR_index'] = result_df['TSR_index'].astype(int)\n",
    "\n",
    "# Sort by sentence for easier reading\n",
    "result_df = result_df.sort_values('sentence').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save unique sentences with task indices to a CSV file\n",
    "csv_path = 'zuco_unique_sentences_with_task_indices.csv'\n",
    "result_df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV to DATALOADER\n",
    "\n",
    "We are going to need to tokenize. For transformer lens, we can see the models which are available in the [model properties table](https://transformerlensorg.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "\n",
    "Let's start with GPT2-medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title: csv file and MODEL\n",
    "csv_path = 'zuco_unique_sentences_with_task_indices.csv'\n",
    "model_name = 'gpt2-medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2-medium data loader \n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "transform = TokenizerTransform(tokenizer) \n",
    "\n",
    "dataloader = get_zuco_sentence_dataloader(\n",
    "    csv_path=csv_path,\n",
    "    transform=transform,\n",
    "    batch_size=15,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing out the dataloader\n",
    "\n",
    "\n",
    "# Example of iterating through the dataloader\n",
    "for batch in dataloader:\n",
    "    sentences = batch['sentence']\n",
    "    in_nr = batch['in_NR']\n",
    "    in_tsr = batch['in_TSR']\n",
    "    NR_indices = batch['NR_index']\n",
    "    TSR_indices = batch['TSR_index']\n",
    "    \n",
    "   # Your model processing here...\n",
    "    # ...\n",
    "    \n",
    "    # Just for demonstration\n",
    "    print(f\"Batch of {len(sentences)} sentences\")\n",
    "    print(f\"Number in NR task: {in_nr.sum().item()}\")\n",
    "    print(f\"NR indices: {NR_indices}\")\n",
    "    print(f\"Number in TSR task: {in_tsr.sum().item()}\")\n",
    "    print(f\"TSR indices: {TSR_indices}\")\n",
    "\n",
    "    print(f\"Sample sentence: {sentences[0]}\")\n",
    "    break  # Just show one batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2-medium with transformer lens- collect activations\n",
    "For Transformer-lens demos, see their [github page](https://github.com/TransformerLensOrg/TransformerLens/tree/main/demos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x14db51910>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False) # don't need gradients for this (not training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model gpt2-medium using TransformerLens on cpu...\n",
      "Loaded pretrained model gpt2-medium into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  12%|█▏        | 5/42 [03:19<23:55, 38.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to embeddings/zuco_gpt2_medium_embeddings.checkpoint_5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  24%|██▍       | 10/42 [06:32<21:22, 40.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to embeddings/zuco_gpt2_medium_embeddings.checkpoint_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  36%|███▌      | 15/42 [09:12<14:48, 32.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to embeddings/zuco_gpt2_medium_embeddings.checkpoint_15.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  48%|████▊     | 20/42 [11:28<10:30, 28.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to embeddings/zuco_gpt2_medium_embeddings.checkpoint_20.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  60%|█████▉    | 25/42 [14:02<08:57, 31.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to embeddings/zuco_gpt2_medium_embeddings.checkpoint_25.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  71%|███████▏  | 30/42 [16:51<06:52, 34.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to embeddings/zuco_gpt2_medium_embeddings.checkpoint_30.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  83%|████████▎ | 35/42 [19:40<03:54, 33.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to embeddings/zuco_gpt2_medium_embeddings.checkpoint_35.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  95%|█████████▌| 40/42 [22:08<01:01, 30.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to embeddings/zuco_gpt2_medium_embeddings.checkpoint_40.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 42/42 [23:03<00:00, 32.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final embeddings saved to embeddings/zuco_gpt2_medium_embeddings.pt\n",
      "Extracted embeddings for 663 sentences\n"
     ]
    }
   ],
   "source": [
    "# Example: Extract embeddings for all sentences in Zuco dataset\n",
    "csv_path = \"zuco_unique_sentences_with_task_indices.csv\"\n",
    "model_name = \"gpt2-medium\"\n",
    "layers = [12,20,23]  # Example: first, middle, and last layers\n",
    "os.makedirs(\"embeddings\", exist_ok=True)  # Create directory if it doesn't exist\n",
    "save_path = \"embeddings/zuco_gpt2_medium_embeddings.pt\"\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Extract embeddings with sliding window (Goldstein approach)\n",
    "# Using the dataloader method\n",
    "embeddings = extract_embeddings_with_dataloader(\n",
    "    csv_path=csv_path,\n",
    "    model_name=model_name,\n",
    "    layers=layers,\n",
    "    sliding_window=True,\n",
    "    batch_size=16,\n",
    "    include_attn=False,\n",
    "    save_path=save_path,\n",
    "    save_separate_batches=False  # Set to True for large datasets or distributed processing\n",
    ")\n",
    "\n",
    "print(f\"Extracted embeddings for {len(embeddings)} sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MISC (unused/testing code - can ignore this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_running_the_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-medium into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# load model \n",
    "model = HookedTransformer.from_pretrained(model_name) # note that model name is defined above with the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: gpt2-medium\n",
      "Number of layers: 24\n",
      "Number of heads: 16\n",
      "Context length: 1024\n",
      "Hidden size: 1024\n",
      "MLP intermediate size: 4096\n",
      "Vocabulary size: 50257\n"
     ]
    }
   ],
   "source": [
    "# Basic model information\n",
    "print(f\"Model name: {model.cfg.model_name}\")\n",
    "print(f\"Number of layers: {model.cfg.n_layers}\")\n",
    "print(f\"Number of heads: {model.cfg.n_heads}\")\n",
    "print(f\"Context length: {model.cfg.n_ctx}\")\n",
    "print(f\"Hidden size: {model.cfg.d_model}\")\n",
    "print(f\"MLP intermediate size: {model.cfg.d_mlp}\")\n",
    "print(f\"Vocabulary size: {model.cfg.d_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from TransformerLens/demos/Interactive_Neuroscope.ipynb\n",
    "def get_layer_acts(model, text, layer=0, neuron_index=None):\n",
    "    cache = {}\n",
    "\n",
    "    def caching_hook(act, hook):\n",
    "        if neuron_index:\n",
    "            cache[\"activation\"] = act[:, :, neuron_index]\n",
    "        else: \n",
    "            cache[\"activation\"] = act\n",
    "\n",
    "    model.run_with_hooks(\n",
    "        text, fwd_hooks=[(f\"blocks.{layer}.mlp.hook_post\", caching_hook)]\n",
    "    )\n",
    "    return utils.to_numpy(cache[\"activation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of 15 sentences\n",
      "Number in NR task: 9\n",
      "NR indices: tensor([  92,    0,  135, -100, -100, -100,   96, -100,   18, -100,   47, -100,\n",
      "         325,   46,  137])\n",
      "Number in TSR task: 10\n",
      "TSR indices: tensor([  30,  354, -100,   24,  118,  244,  193,  360,  259,  383, -100,  186,\n",
      "        -100, -100, -100])\n",
      "Sample sentence: The contest between the two was bitter, although they differed little on issues.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 7\n",
      "NR indices: tensor([-100, -100,  314,  204,   14, -100, -100, -100, -100,  178, -100,  293,\n",
      "         324,  345, -100])\n",
      "Number in TSR task: 9\n",
      "TSR indices: tensor([  56,   29, -100, -100, -100,  102,  329,  256,  143,  230,   69, -100,\n",
      "        -100, -100,  248])\n",
      "Sample sentence: His long academic career included 37 years at the University of Wales, Swansea, between 1945 and 1982, and ten as vice-president of the University College of Wales, Aberystwyth.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 7\n",
      "NR indices: tensor([ 173, -100,  245,  321, -100,  328,   28, -100, -100, -100, -100,   90,\n",
      "        -100,   60, -100])\n",
      "Number in TSR task: 9\n",
      "TSR indices: tensor([-100,  138, -100, -100,  114,  242, -100,   70,  306,   48,   97, -100,\n",
      "          73, -100,  108])\n",
      "Sample sentence: Despite Charles's reputation as a womaniser, Catherine never gave birth to a live heir, though she had several pregnancies, the last being in 1669.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 5\n",
      "NR indices: tensor([-100, -100,  335, -100,  255, -100, -100,   75, -100, -100, -100, -100,\n",
      "          35,   86, -100])\n",
      "Number in TSR task: 11\n",
      "TSR indices: tensor([  60,  370, -100,   35, -100,  375,  176, -100,   85,  201,   54,  364,\n",
      "         277, -100,  358])\n",
      "Sample sentence: In 1926, King started his ministerial degree at the Morehouse School of Religion.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 7\n",
      "NR indices: tensor([ 219,  104,    6,  136, -100, -100, -100, -100,  213, -100, -100,  198,\n",
      "        -100,  222, -100])\n",
      "Number in TSR task: 9\n",
      "TSR indices: tensor([ 366, -100, -100, -100,  268,  171,  264,  164, -100,   99,   80, -100,\n",
      "          28, -100,  155])\n",
      "Sample sentence: Jack didn't start to learn English until the age of six.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 5\n",
      "NR indices: tensor([ 177, -100,   55,   17, -100, -100, -100, -100,  298, -100, -100,  134,\n",
      "        -100, -100, -100])\n",
      "Number in TSR task: 11\n",
      "TSR indices: tensor([ 123,   93, -100, -100,  374,  238,  224,  352, -100,  371,  320, -100,\n",
      "         237,   94,   21])\n",
      "Sample sentence: Laurance married Mary French in 1934.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 7\n",
      "NR indices: tensor([  11,  127, -100,  333, -100,  305, -100, -100, -100, -100,  168,   54,\n",
      "        -100, -100,  106])\n",
      "Number in TSR task: 8\n",
      "TSR indices: tensor([-100, -100,   12, -100,  106, -100,  293,  166,  140,  169, -100, -100,\n",
      "         208,  205, -100])\n",
      "Sample sentence: Although Ford is often credited with the idea, contemporary sources indicate that the concept and its development came from employees Clarence Avery, Peter E. Martin, Charles E. Sorensen, and C.H. Wills.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 8\n",
      "NR indices: tensor([ 304, -100, -100,   30, -100,  281,  121, -100,  253,  102, -100,  284,\n",
      "         206, -100, -100])\n",
      "Number in TSR task: 8\n",
      "TSR indices: tensor([-100,   22,  145,  272,  192, -100, -100,  239, -100, -100,  249, -100,\n",
      "        -100,   72,  234])\n",
      "Sample sentence: He was inducted into the College Football Hall of Fame, the South Carolina Sports Hall of Fame, and the Clemson Ring of Honor.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 8\n",
      "NR indices: tensor([  68, -100,  115, -100,  277,  114, -100, -100,  246, -100, -100,   15,\n",
      "         116, -100,  201])\n",
      "Number in TSR task: 7\n",
      "TSR indices: tensor([-100,  149, -100,   23, -100, -100,  353,   38, -100,  139,  245, -100,\n",
      "        -100,  144, -100])\n",
      "Sample sentence: Struensee was arrested and executed in that same year.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 10\n",
      "NR indices: tensor([ 279,  217,  347,  247, -100,    5, -100,  224,  260, -100, -100,  139,\n",
      "          69, -100,  239])\n",
      "Number in TSR task: 6\n",
      "TSR indices: tensor([-100, -100,  127, -100,  167, -100,  189, -100, -100,  221,   71, -100,\n",
      "        -100,   53, -100])\n",
      "Sample sentence: Cheney's former chief of staff, Lewis Libby, is one of the main figures under investigation.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 10\n",
      "NR indices: tensor([ 122, -100,  174, -100,  322,  226,  285, -100, -100,  220, -100,  158,\n",
      "         129,   21,  340])\n",
      "Number in TSR task: 8\n",
      "TSR indices: tensor([ 351,   27, -100,   58,  291, -100, -100,   11,  162, -100,   33, -100,\n",
      "        -100, -100,  105])\n",
      "Sample sentence: He died, however, aboard ship and was given a sea burial.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 9\n",
      "NR indices: tensor([ 262,  130, -100,  261, -100,    9,   56,  329, -100, -100,  225, -100,\n",
      "        -100,   84,  264])\n",
      "Number in TSR task: 7\n",
      "TSR indices: tensor([-100, -100,  181, -100,  209, -100, -100,   42,  206,  231, -100,  369,\n",
      "         190, -100, -100])\n",
      "Sample sentence: At the time, it was not possible for the authorities in each area to link the two convictions which would have resulted in the second offence being viewed much more seriously.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 6\n",
      "NR indices: tensor([-100,  172,  119, -100, -100, -100,  208, -100,  283, -100, -100, -100,\n",
      "         242, -100,   53])\n",
      "Number in TSR task: 10\n",
      "TSR indices: tensor([  90, -100,  241,  220,  281,  168, -100,  294, -100,  195,  323,  148,\n",
      "        -100,  278, -100])\n",
      "Sample sentence: He then went on to attend and subsequently drop out of Georgetown University Law Center (1957).\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 2\n",
      "NR indices: tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,  346,\n",
      "        -100, -100,   16])\n",
      "Number in TSR task: 14\n",
      "TSR indices: tensor([ 152,  253,  217,  116,  322,  279,  246,   67,  194,  285,  341, -100,\n",
      "         147,  309,  334])\n",
      "Sample sentence: Presley married her first husband Danny Keough on October 3, 1988.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 6\n",
      "NR indices: tensor([-100, -100, -100, -100, -100,  303, -100, -100,   91, -100,   34,   38,\n",
      "         188, -100,  165])\n",
      "Number in TSR task: 11\n",
      "TSR indices: tensor([ 304,   95,  378,    3,  226,  260,   79,  225, -100,  203,  276, -100,\n",
      "        -100,  252, -100])\n",
      "Sample sentence: Kurt Donald Cobain (February 20, 1967 – ca. April 5, 1994) was the lead singer and guitarist of the American rock band, Nirvana.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 7\n",
      "NR indices: tensor([-100,  200, -100, -100,  309,   43,   48,  118,  186, -100, -100,  166,\n",
      "        -100, -100, -100])\n",
      "Number in TSR task: 9\n",
      "TSR indices: tensor([   1, -100,  327,  184, -100, -100, -100, -100, -100,  136,    2,  212,\n",
      "         376,  141,   49])\n",
      "Sample sentence: He was buried at the foot of Hill Cemetery.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 4\n",
      "NR indices: tensor([ 113, -100, -100, -100, -100,   37, -100,  291, -100, -100, -100, -100,\n",
      "        -100, -100,  348])\n",
      "Number in TSR task: 11\n",
      "TSR indices: tensor([-100,   65,    7,  182,   18, -100,  179, -100,  379,  289,  161,   34,\n",
      "           9,  388, -100])\n",
      "Sample sentence: No Barrymore would allow such a conventional thing to happen to him.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 7\n",
      "NR indices: tensor([-100, -100, -100,  313,  199, -100,    4, -100,   27,  257, -100, -100,\n",
      "         214,  230, -100])\n",
      "Number in TSR task: 9\n",
      "TSR indices: tensor([ 331,  160,   55, -100, -100,  151, -100,  265,  271, -100,  324,  115,\n",
      "        -100, -100,   31])\n",
      "Sample sentence: Joely Fisher (born October 29, 1967) is an American actress.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 6\n",
      "NR indices: tensor([-100,   32, -100,  250, -100, -100, -100, -100, -100,  332, -100, -100,\n",
      "          22,  269,   65])\n",
      "Number in TSR task: 11\n",
      "TSR indices: tensor([ 183,  274,  187, -100,  344,  235,  302,  142,  173, -100,  132,   16,\n",
      "        -100,   78, -100])\n",
      "Sample sentence: Michel Goulet (born April 21, 1960 in Peribonka, Quebec) was a Canadian professional ice hockey forward who played for the Quebec Nordiques and Chicago Blackhawks in the National Hockey League.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 11\n",
      "NR indices: tensor([-100,  286,  169,  105,  211,  289,  274,  259,  266, -100, -100, -100,\n",
      "          33,  343,  107])\n",
      "Number in TSR task: 6\n",
      "TSR indices: tensor([  64, -100, -100,  243, -100, -100, -100, -100, -100,   88,  316,  305,\n",
      "         275, -100, -100])\n",
      "Sample sentence: He was born in Montpelier, Vermont, attended Norwich University for two years (1852-1854), and graduated from the Naval Academy in 1858.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 11\n",
      "NR indices: tensor([ 330,  337,   57, -100,  123,  191, -100,  143,  124, -100,  109,  103,\n",
      "        -100,   24,  167])\n",
      "Number in TSR task: 6\n",
      "TSR indices: tensor([-100, -100, -100,  298,  191, -100,   41, -100,  240,   47, -100, -100,\n",
      "         336, -100, -100])\n",
      "Sample sentence: He is a prominent member of the Bush family, the younger brother of President George W. Bush and the second son of former President George H. W. Bush and Barbara Bush.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 10\n",
      "NR indices: tensor([-100,  338,  160,   99,   87, -100,  296,  205,   95,  175,  133,  215,\n",
      "        -100, -100, -100])\n",
      "Number in TSR task: 6\n",
      "TSR indices: tensor([ 384,  103, -100, -100, -100,  387, -100, -100, -100, -100, -100, -100,\n",
      "         288,  346,   87])\n",
      "Sample sentence: He also created the Defense Intelligence Agency and the Defense Supply Agency.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 8\n",
      "NR indices: tensor([ 101,  295,  128, -100,  192, -100, -100,   78,  235, -100,  248, -100,\n",
      "         152, -100, -100])\n",
      "Number in TSR task: 7\n",
      "TSR indices: tensor([-100, -100, -100,  233, -100,  129,   86, -100, -100,   81, -100,  372,\n",
      "        -100,  218,  154])\n",
      "Sample sentence: Their greed leads to distrust and dishonesty, and eventually the society crumbles.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 7\n",
      "NR indices: tensor([-100, -100, -100, -100,   66, -100,   51,  190,   89,  117, -100, -100,\n",
      "         187, -100,  151])\n",
      "Number in TSR task: 9\n",
      "TSR indices: tensor([ 330,   50,  343,  380, -100,  180, -100, -100, -100, -100,  321,  196,\n",
      "          25,  113, -100])\n",
      "Sample sentence: Alexander Gretchaninoff (October 25, 1864 Moscow, – January 3, 1956 New York) was a Russian Romantic composer, a student of Sergei Taneyev and Nikolai Rimsky-Korsakov known for his children's music, and also for his liturgical and other choral music.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 9\n",
      "NR indices: tensor([ 306, -100, -100,   93,   44,  156,  159, -100,  263, -100,    3,   98,\n",
      "        -100,  197, -100])\n",
      "Number in TSR task: 7\n",
      "TSR indices: tensor([-100,  202,   43, -100, -100, -100, -100,  251, -100,  134, -100,   36,\n",
      "         222, -100,  188])\n",
      "Sample sentence: John Fitzgerald Kennedy (May 29, 1917 - November 22, 1963), often referred to as Jack Kennedy or JFK, was the 35th President of the United States.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 5\n",
      "NR indices: tensor([-100, -100, -100, -100,  181,  179,  157, -100,  171, -100,  170, -100,\n",
      "        -100, -100, -100])\n",
      "Number in TSR task: 10\n",
      "TSR indices: tensor([ 350,   13,  227,  117, -100, -100, -100,    6, -100,  200, -100,  317,\n",
      "          68,    0,  172])\n",
      "Sample sentence: In 1736 he created the Union Fire Company, the first volunteer firefighting company in America.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 6\n",
      "NR indices: tensor([ 142, -100,   61,   50, -100,  154, -100,  233, -100, -100, -100, -100,\n",
      "          39, -100, -100])\n",
      "Number in TSR task: 10\n",
      "TSR indices: tensor([-100,  326, -100, -100,  107, -100,  262,  165,  135,  175,  207,  389,\n",
      "        -100,  198,  137])\n",
      "Sample sentence: He spends a great deal of his time at Moe's Tavern with his lifelong friends Barney, Carl, Lenny, and bartender Moe.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 11\n",
      "NR indices: tensor([-100,  140,   73,  193,   79, -100, -100,  252,  111,  153,  227,  162,\n",
      "         145,  251, -100])\n",
      "Number in TSR task: 5\n",
      "TSR indices: tensor([  98, -100,  292, -100, -100,   77,  297, -100, -100, -100, -100, -100,\n",
      "        -100, -100,   66])\n",
      "Sample sentence: William studied law at the Inns of Court in London, returning to Maryland in 1765.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 10\n",
      "NR indices: tensor([ 100, -100, -100,  336,  138, -100,  149,  234,  254,  223,  184, -100,\n",
      "        -100,   49,  300])\n",
      "Number in TSR task: 7\n",
      "TSR indices: tensor([-100,  199,  197, -100, -100,  283, -100, -100, -100, -100,   15,  111,\n",
      "         124,  363, -100])\n",
      "Sample sentence: As their desire for wealth grows, they discard spiritual and creative values.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 6\n",
      "NR indices: tensor([  13, -100, -100,  148, -100,  196, -100,  272, -100, -100, -100, -100,\n",
      "          41, -100,  316])\n",
      "Number in TSR task: 9\n",
      "TSR indices: tensor([-100,  273,  121, -100,  349, -100,  286, -100,  211,  213,  261,  282,\n",
      "        -100,  280, -100])\n",
      "Sample sentence: Edsel's widow Eleanor, who had inherited Edsel's voting stock, wanted her son Henry Ford II to take over the position.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 7\n",
      "NR indices: tensor([-100, -100, -100,  231,  292, -100,  210,  244, -100, -100, -100,  294,\n",
      "        -100,  236,  331])\n",
      "Number in TSR task: 11\n",
      "TSR indices: tensor([  76,   39,   10,  125, -100,  204,  120, -100,  110,  156,  303, -100,\n",
      "         254, -100,  284])\n",
      "Sample sentence: He studied at Juilliard and later at the Manhattan School of Music.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 10\n",
      "NR indices: tensor([ 297,  317,    8,  241, -100,  120,  183,  327,  131, -100,   52, -100,\n",
      "        -100,  344, -100])\n",
      "Number in TSR task: 8\n",
      "TSR indices: tensor([-100, -100, -100, -100,  157,  267, -100, -100,  133,  104,  236,  347,\n",
      "         158, -100,  255])\n",
      "Sample sentence: Lawford's first major movie role was A Yank At Eton (1942).\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 5\n",
      "NR indices: tensor([-100, -100,  326,  150, -100, -100, -100,  229, -100, -100, -100,   85,\n",
      "        -100, -100,   64])\n",
      "Number in TSR task: 10\n",
      "TSR indices: tensor([  61,  159, -100, -100,  131,  382,   91, -100,   96,  210,   32, -100,\n",
      "         130,  128, -100])\n",
      "Sample sentence: His father, Richert Vogt von Koch (1838-1913) was a Lieutenant-Colonel in the Royal Horse Guards of Sweden.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 11\n",
      "NR indices: tensor([ 280, -100, -100,  132,  228,  342,  147,  237,  108,  221,   19, -100,\n",
      "        -100,    7,   31])\n",
      "Number in TSR task: 6\n",
      "TSR indices: tensor([-100,  355,  335, -100, -100, -100, -100, -100, -100,  119,  122,  216,\n",
      "         301, -100, -100])\n",
      "Sample sentence: On October 28, Libby was indicted on five felony counts.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 8\n",
      "NR indices: tensor([-100,   74,  311, -100, -100,  275, -100, -100,  258,  307, -100,  238,\n",
      "        -100,   70,  164])\n",
      "Number in TSR task: 8\n",
      "TSR indices: tensor([  62, -100, -100,  325,  112, -100,  170,  345, -100, -100,  101, -100,\n",
      "         308, -100,  174])\n",
      "Sample sentence: He graduated Phi Beta Kappa and magna cum laude (21st of 177) from Harvard University in 1880, and entered Columbia Law School that same year.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 7\n",
      "NR indices: tensor([-100,  202, -100,   88,  339, -100, -100,  273, -100, -100,  163,   29,\n",
      "        -100, -100,   10])\n",
      "Number in TSR task: 8\n",
      "TSR indices: tensor([ 163, -100,   44, -100, -100,  381,  340, -100,  314,   19, -100, -100,\n",
      "         332,   63, -100])\n",
      "Sample sentence: Grace Anna Goodhue Coolidge (January 3, 1879 – July 8, 1957) was wife of Calvin Coolidge and First Lady of the United States from 1923 to 1929.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 8\n",
      "NR indices: tensor([  59, -100,  319, -100, -100, -100,  315,  141,   58, -100, -100,   26,\n",
      "        -100,   20,  232])\n",
      "Number in TSR task: 10\n",
      "TSR indices: tensor([ 328,   89, -100,  146,  229,  337, -100, -100, -100,  333,   82, -100,\n",
      "          45,   37,  150])\n",
      "Sample sentence: Taylor was born with dual British and American citizenship.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 10\n",
      "NR indices: tensor([-100,   80,  212, -100, -100,  290,  323,  185,  278, -100,  126, -100,\n",
      "          71,  249,  144])\n",
      "Number in TSR task: 6\n",
      "TSR indices: tensor([  74, -100, -100,   51,  365, -100, -100,   20, -100,  215, -100,  385,\n",
      "        -100, -100, -100])\n",
      "Sample sentence: Despite the poverty he grew up in, he managed to win a scholarship to the Laurinburg Institute in North Carolina.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 7\n",
      "NR indices: tensor([-100, -100, -100,  203, -100, -100,  155,  276,  271, -100,   72, -100,\n",
      "         125, -100,  243])\n",
      "Number in TSR task: 10\n",
      "TSR indices: tensor([ 290,  232,   26, -100,  359,   83,  223, -100, -100,  178,  185,  307,\n",
      "        -100,  377, -100])\n",
      "Sample sentence: Friedrich Wilhelm Bessel (July 22, 1784 – March 17, 1846) was a German mathematician, astronomer, and systematizer of the Bessel functions (which, despite their name, were discovered by Daniel Bernoulli).\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 9\n",
      "NR indices: tensor([  77, -100,  218, -100,  341, -100,   81,  268, -100,  176, -100,   82,\n",
      "         209, -100,  334])\n",
      "Number in TSR task: 8\n",
      "TSR indices: tensor([-100,   57, -100,  219, -100,  339, -100,   52,  367, -100,  100, -100,\n",
      "        -100,  153,  386])\n",
      "Sample sentence: In 1958 Ferrer appeared in I Accuse!\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 14\n",
      "NR indices: tensor([ 207,  299, -100,   76,  182,   23,  270,  161,  308,   12,   25,   36,\n",
      "         287,  302,   62])\n",
      "Number in TSR task: 1\n",
      "TSR indices: tensor([-100, -100,  368, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100])\n",
      "Sample sentence: Hodgkin and Huxley shared the prize that year with John Carew Eccles, who was cited for research on synapses.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 8\n",
      "NR indices: tensor([-100, -100, -100, -100,  194, -100,   67,   40,  288, -100,    1,    2,\n",
      "         146,  301, -100])\n",
      "Number in TSR task: 10\n",
      "TSR indices: tensor([  14,   17,  270,  373, -100,    8, -100, -100, -100,  214,  356,  357,\n",
      "        -100,  338,  109])\n",
      "Sample sentence: Samuel Adams (5 June 1805 - 27 February 1850) was a Democratic Governor of the State of Arkansas.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 6\n",
      "NR indices: tensor([-100,  110,  240, -100,   63, -100, -100,  282,  216,   42, -100, -100,\n",
      "        -100, -100, -100])\n",
      "Number in TSR task: 11\n",
      "TSR indices: tensor([ 126, -100, -100,   75,  348,   84,  362, -100,  361, -100,    5,   40,\n",
      "           4,  257,  287])\n",
      "Sample sentence: In this year Encke married Amalie Becker (1787–1879), daughter of a bookseller.\n",
      "Batch of 15 sentences\n",
      "Number in NR task: 9\n",
      "NR indices: tensor([ 310,  265, -100,  256, -100,   45, -100,  267,   94,   83,  195,  189,\n",
      "        -100, -100, -100])\n",
      "Number in TSR task: 6\n",
      "TSR indices: tensor([-100, -100,   59, -100,  250, -100,  177, -100, -100, -100, -100, -100,\n",
      "         296,  266,   46])\n",
      "Sample sentence: Another example of Kennedy's belief in the ability of nonmilitary power to improve the world was the creation of the Peace Corps, one of his first acts as president.\n",
      "Batch of 3 sentences\n",
      "Number in NR task: 1\n",
      "NR indices: tensor([-100,  180, -100])\n",
      "Number in TSR task: 2\n",
      "TSR indices: tensor([ 269, -100,   92])\n",
      "Sample sentence: She was a press officer at the Greater London Council [1985 to 1986].\n"
     ]
    }
   ],
   "source": [
    "# save activations\n",
    "sentences_NR_idx = []\n",
    "sentences_TSR_idx = []\n",
    "my_layer_acts = []\n",
    "\n",
    "\n",
    "for batch in dataloader:\n",
    "    sentences = batch['sentence']\n",
    "    in_nr = batch['in_NR']\n",
    "    in_tsr = batch['in_TSR']\n",
    "    NR_indices = batch['NR_index']\n",
    "    TSR_indices = batch['TSR_index']\n",
    "    \n",
    "    sentences_NR_idx.append(NR_indices)\n",
    "    sentences_TSR_idx.append(TSR_indices)\n",
    "\n",
    "    # get layer activations\n",
    "    my_layer_acts.append(get_layer_acts(model, sentences, layer=23, neuron_index=None))\n",
    "    # Just for demonstration\n",
    "    print(f\"Batch of {len(sentences)} sentences\")\n",
    "    print(f\"Number in NR task: {in_nr.sum().item()}\")\n",
    "    print(f\"NR indices: {NR_indices}\")\n",
    "    print(f\"Number in TSR task: {in_tsr.sum().item()}\")\n",
    "    print(f\"TSR indices: {TSR_indices}\")\n",
    "\n",
    "    print(f\"Sample sentence: {sentences[0]}\")\n",
    "    # Just show one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 54, 4096)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by task and index\n",
    "all_sentences_df = all_sentences_df.sort_values(by=['task', 'index'])\n",
    "\n",
    "# Now you can easily filter by task, subject, get unique sentences, etc.\n",
    "nr_sentences = all_sentences_df[all_sentences_df['task'] == 'NR']\n",
    "subject_tsr_sentences = all_sentences_df[(all_sentences_df['task'] == 'TSR') & \n",
    "                                        (all_sentences_df['subject'] == 'YAC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ZucoDataLoader()\n",
    "\n",
    "# Example: get all features\n",
    "all_features = loader.get_features()\n",
    "\n",
    "# Example: get features for a specific feature set\n",
    "electrode_features = loader.get_features(feature_set='electrode_features_all')\n",
    "\n",
    "# Example: get features for specific subjects\n",
    "selected_subjects_features = loader.get_features(\n",
    "    feature_set='sent_gaze_sacc', \n",
    "    subjects=['YAC', 'YDR']\n",
    ")\n",
    "\n",
    "# Example: get stimulus for all subjects\n",
    "all_stimulus = loader.get_stimulus()\n",
    "\n",
    "# Example: get stimulus for specific subjects and task\n",
    "specific_stimulus = loader.get_stimulus(\n",
    "    subjects=['YAC', 'YDR'], \n",
    "    task='NR'\n",
    ")\n",
    "\n",
    "# Print some details about the loaded dataset\n",
    "print(\"Available Feature Sets:\", list(loader.data['features'].keys()))\n",
    "print(\"Total Subjects:\", len(loader.metadata['subjects']))\n",
    "print(\"Channel Locations:\", loader.metadata['channel_locations'])\n",
    "print(\"Stimulus Example:\", specific_stimulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title save csv - not good - the nan's are a problem\n",
    "\n",
    "# We want to get the senteces out for an LLM, so we only need the unique sentences. \n",
    "# We should however, keep track of the sentence index and which task(s) it was used in \n",
    "\n",
    "# Create two separate DataFrames for each task\n",
    "nr_df = df2[df2['task'] == 'NR'][['index', 'sentence']].rename(columns={'index': 'NR_index'})\n",
    "tsr_df = df2[df2['task'] == 'TSR'][['index', 'sentence']].rename(columns={'index': 'TSR_index'})\n",
    "\n",
    "# Merge the DataFrames on the sentence, using outer join to keep all sentences\n",
    "result_df = pd.merge(nr_df, tsr_df, on='sentence', how='outer')\n",
    "\n",
    "# Sort by sentence for easier reading\n",
    "result_df = result_df.sort_values('sentence').reset_index(drop=True)\n",
    "\n",
    "# Print summary statistics\n",
    "nr_only = result_df[result_df['TSR_index'].isna()].shape[0]\n",
    "tsr_only = result_df[result_df['NR_index'].isna()].shape[0]\n",
    "both = result_df.dropna().shape[0]\n",
    "\n",
    "print(f\"Total unique sentences: {len(result_df)}\")\n",
    "print(f\"Sentences in NR only: {nr_only}\")\n",
    "print(f\"Sentences in TSR only: {tsr_only}\")\n",
    "print(f\"Sentences in both tasks: {both}\")\n",
    "\n",
    "# Preview the data\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(result_df.head())\n",
    "\n",
    "# Preview overlapping sentences\n",
    "print(\"\\nSample of sentences appearing in both tasks:\")\n",
    "print(result_df.dropna().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
